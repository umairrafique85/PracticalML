library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("caret")
View(segmentationOriginal)
library(caret)
?createDataPartition
table(segmentationOriginal$Case)
set.seed(125)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
rpart
library(rpart)
?rpart
View(head(segmentationOriginal))
model1 <- rpart(Class ~ ., data = train)
predict(model1, newdata = data.frame(TotalIntench2 = c(23000, 50000, 57000),
FiberWidthCh1 = c(10, 10, 8),
PerimStatusCh1 = c(2, 100, 100)))
names(train)
predict(model1, newdata = data.frame(TotalIntenCh2 = c(23000, 50000, 57000),
FiberWidthCh1 = c(10, 10, 8),
PerimStatusCh1 = c(2, 100, 100)))
View(model1)
plot(model1)
set.seed(125)
model1 <- rpart(Class ~ ., data = train[, -c("Cell", "Case")])
set.seed(125)
model1 <- rpart(Class ~ ., data = select(train[, -c(1:2)])
set.seed(125)
model1 <- rpart(Class ~ ., data = train[, -c(1:2)])
predict(model1, newdata = data.frame())
set.seed(125)
model1 <- rpart(Class ~ TotalIntenCh2 + FiberWidthCh1 + PerimStatusCh1,
data = train[, -c(1:2)])
predict(model1, newdata = data.frame(TotalIntenCh2 = c(23000, 50000, 57000),
FiberWidthCh1 = c(10, 10, 8),
PerimStatusCh1 = c(2, 100, 100)))
predict(model1, newdata = data.frame(TotalIntenCh2 = 23000,
FiberWidthCh1 = 10,
PerimStatusCh1 = 2))
predict(model1, newdata = data.frame(TotalIntenCh2 = 50000,
FiberWidthCh1 = 10,
VarIntenCh4 = 2))
predict(model1, newdata = data.frame(TotalIntenCh2 = 57000,
FiberWidthCh1 = 8,
VarIntenCh4 = 100))
?rpart
model1 <- rpart(Class ~ .,data = segmentationOriginal, split = Case)
model1 <- rpart(Class ~ ., data = segmentationOriginal, split = "Case")
model1 <- rpart(Class ~ ., data = segmentationOriginal)
library(dplyr)
train <- filter(segmentationOriginal, Case == "Train") %>%
select(-c(Cell, Case))
test <- filter(segmentationOriginal, Case == "Test") %>%
select(-c(Cell, Case))
set.seed(125)
model1 <- rpart(Class ~ ., data = train)
predict(model1, newdata = data.frame(TotalIntenCh2 = 23000,
FiberWidthCh1 = 10,
PerimStatusCh1 = 2))
library(caret)
model1 <- caret::train(Class ~ ., data = train, method = 'rpart')
install.packages("e1071")
model1 <- caret::train(Class ~ ., data = train, method = 'rpart')
set.seed(125)
model1 <- caret::train(Class ~ ., data = train, method = 'rpart')
predict(model1, newdata = data.frame(TotalIntenCh2 = 23000,
FiberWidthCh1 = 10,
PerimStatusCh1 = 2))
predict(model1$finalModel, newdata = data.frame(TotalIntenCh2 = 23000,
FiberWidthCh1 = 10,
PerimStatusCh1 = 2))
q('no')
getwd()
df_tasting <- read.csv("projects/fiverr/ediblesci/Tasting.csv")
names(df_tasting)
View(df_tasting)
table(df_tasting$Treatment)
table(df_tasting$Taster)
table(df_tasting$Origin)
q('no')
getwd()
read.csv("projects/fiverr/ediblesci")
read.csv("projects/fiverr/ediblesci/Tasting.csv")
df_tasting <- read.csv("projects/fiverr/ediblesci/Tasting.csv")
View(df_tasting)
names(df_tasting)
q('yes')
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
# from Solution
subset <- split(segmentationOriginal, segmentationOriginal$Case)
set.seed(125)
modCART <- rpart(Class ~ ., data=subset$Train)
library(rpart)
modCART <- rpart(Class ~ ., data=subset$Train)
modCART
testA <- segmentationOriginal[0,]
View(testA)
testA[1,c("TotalIntenCh2", "FiberWidthCh1", "PerimStatusCh1")] <- c(23000, 10, 2)
predict(modCART, testA, type="prob")
testB <- segmentationOriginal[0,]
testB[1,c("TotalIntenCh2", "FiberWidthCh1", "VarIntenCh4")] <- c(50000, 10, 100)
predict(modCART, testB, type="prob")
testC <- segmentationOriginal[0,]
testC[1,c("TotalIntenCh2", "FiberWidthCh1", "VarIntenCh4")] <- c(57000, 8, 100)
predict(modCART, testC, type="prob")
testD <- segmentationOriginal[0,]
testD[1,c("FiberWidthCh1", "VarIntenCh4","PerimStatusCh1")] <- c(8, 100, 2)
predict(modCART, testD, type="prob")
library(pgmm)
data("olive")
olive <- olive[, -1]
View(olive)
data("olive")
View(olive)
olive <- olive[, -1]
newData <- as.data.frame(t(colMeans(olive)))
View(colMeans(olive))
source('~/.active-rstudio-document', echo=TRUE)
predict(modFit2, newdata = newData)
table(olive$Area)
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
train <- sample(1:dim(SAheart)[1], size = dim(SAheart)[1]/2, replace = F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
fit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA,
method="glm", family="binomial")
table(trainSA$chd)
missClass <- function(values, prediction) {
sum(((prediction > 0.5)*1) != values)/length(values)
}
missClass(testSA$chd, predict(fit, testSA))
missClass(trainSA$chd, predict(fit))
data("vowel.train")
data("vowel.test")
View(vowel.train)
vowel.train$y <- as.factor(vowel.train)
vowel.test$y <- as.factor(vowel.test)
library(randomForest)
fit5 <- randomForest(y ~ ., data = vowel.test)
varImp(fit5)
?varImp
varImpPlot(fit5)
as.data.frame(varImp(fit5))
as.data.frame(varImp(fit5)) %>% arrange(desc(Overall))
library(dplyr)
as.data.frame(varImp(fit5)) %>% arrange(desc(Overall))
arrange(as.data.frame(varImp(fit5)), desc(Overall))
library(tidyverse)
as.data.frame(varImp(fit5)) %>%
rownames_to_column() %>%
arrange(desc(Overall))
set.seed(33833)
?train
mod1_1 <- train(y ~ ., data = vowel.train, method = "rf")
mod1_2 <- train(y ~ ., data = vowel.train, method = "gbm")
mod1_1
mod1_2
confusionMatrix(vowel.test$y, predict(mod1_1, vowel.test))
predict(mod1_1, vowel.test)
class(vowel.train)
class(vowel.train$y)
class(vowel.test$y)
table(vowel.test$y)
table(vowel.test$y)
table(vowel.train$y)
View(vowel.train)
data("vowel.train")
data("vowel.test")
View(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
table(vowel.train$y)
set.seed(33833)
mod1_1 <- train(y ~ ., data = vowel.train, method = "rf")
mod1_2 <- train(y ~ ., data = vowel.train, method = "gbm")
confusionMatrix(vowel.test$y, predict(mod1_1, vowel.test))
confusionMatrix(vowel.test$y, predict(mod1_2, vowel.test))
confusionMatrix(predict(mod1_1, vowel.test), predict(mod1_2, vowel.test))
mod1_1$results$Accuracy
# 2
library(gbm)
set.seed(3433)
data(AlzheimerDisease)
rm(list = ls())
data(AlzheimerDisease)
adData <- data.frame(dignosis, predictors)
adData <- data.frame(diagnosis, predictors)
inTrain <- createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training <- adData[inTrain, ]
source('~/.active-rstudio-document', echo=TRUE)
rm(vowel.test, vowel.train)
testing <- adData[-inTrain, ]
set.seed(62433)
View(training)
mod2_rf <- train(diagnosis ~ ., method = "rf")
mod2_rf <- train(diagnosis ~ ., method = "rf", data = training)
mod2_gbm <- train(diagnosis ~ ., method = "gbm", data = training)
mod2_lda <- train(diagnosis ~ ., method = "lda", data = training)
confusionMatrix(testing$diagnosis, predict(mod2_rf, testing))
confusionMatrix(testing$diagnosis, predict(mod2_gbm, testing))
confusionMatrix(testing$diagnosis, predict(mod2_lda, testing))
confusionMatrix(testing$diagnosis, predict(mod2_lda, testing))$overal['accuracy']
confusionMatrix(testing$diagnosis, predict(mod2_lda, testing))$overall['accuracy']
confusionMatrix(testing$diagnosis, predict(mod2_lda, testing))$overall[1]
stackFrame <- data.frame(diagnosis = testing$diagnosis,
predict(mod2_rf, testing),
predict(mod2_gbm, testing),
predict(mod2_lda, testing))
mod2_stack <- train(diagnosis ~ ., method = "rf", data = stackFrame)
confusionMatrix(testing$diagnosis, predict(mod2_stack, testing))$overall[1]
mod2_stack
confusionMatrix(testing$diagnosis, predict(mod2_lda, testing))$overall[1]
confusionMatrix(testing$diagnosis, predict(mod2_rf, testing))$overall[1]
confusionMatrix(testing$diagnosis, predict(mod2_gbm, testing))$overall[1]
confusionMatrix(testing$diagnosis, predict(mod2_lda, testing))$overall[1]
mod2_stack
mod2_stack$results$Accuracy
stackFrame <- data.frame(diagnosis = training$diagnosis,
predict(mod2_rf),
predict(mod2_gbm),
predict(mod2_lda))
mod2_stack <- train(diagnosis ~ ., method = "rf", data = stackFrame)
confusionMatrix(testing$diagnosis, predict(mod2_stack, testing))$overall[1]
predict(mod2_rf)
mod2_stack$results$Accuracy
confusionMatrix(testing$diagnosis, predict(mod2_stack, testing))
stackFrame <- data.frame(diagnosis = training$diagnosis,
pred1 = predict(mod2_rf),
pred2 = predict(mod2_gbm),
pred3 = predict(mod2_lda))
stackTest <- data.frame(pred1 = predict(mod2_rf, testing),
pred2 = predict(mod2_gbm, testing),
pred3 = predict(mod2_lda, testing))
mod2_stack <- train(diagnosis ~ ., method = "rf", data = stackFrame)
confusionMatrix(testing$diagnosis, predict(mod2_stack, stackTest))
confusionMatrix(testing$diagnosis, predict(mod2_rf, testing))$overall[1]
confusionMatrix(testing$diagnosis, predict(mod2_gbm, testing))$overall[1]
confusionMatrix(testing$diagnosis, predict(mod2_lda, testing))$overall[1]
# 3
set.seed(3523)
rm(list = ls())
data(concrete)
training <- concrete[inTrain,]
inTrain <- createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training <- concrete[inTrain,]
testing <- concrete[-inTrain,]
set.seed(233)
fit3 <- train(CompressiveStrength ~ ., method = 'lasso', data = training)
library(elasticnet)
?plot.enet
plot.enet(fit3)
plot.enet(fit3$finalModel, xvar = "penalty", use.color = TRUE)
# 4
library(lubridate)
dat <- read.csv("Desktop/gaData.csv")
training <- dat[year(dat$date) < 2012,]
testing <- dat[year(dat$date) > 2011, ]
tstrain <- ts(training$visitsTumblr)
install.packages("forecast")
fit4 <- bats(tstrain)
library(forecast)
fit4 <- bats(tstrain)
forecastObj <- forecast(fit4, level=95, h=nrow(testing))
betweenVal <- sum(testing$visitsTumblr > forecastObj$lower &  testing$visitsTumblr < forecastObj$upper)
betweenVal / nrow(testing) * 100
# 4
set.seed(3523)
rm(list = ls())
data("concrete")
inTrain <- createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training <- concrete[inTrain,]
testing <- concrete[-inTrain,]
set.seed(325)
fit5 <- e1071::svm(CompressieStrength ~ ., data = training)
fit5 <- e1071::svm(CompressiveStrength ~ ., data = training)
accuracy(predict(fit5, testing), testing$CompressiveStrength)
rm(list = ls())
library(swirl)
swirl()
play()
names(galton)
nxt()
fit <- lm(child ~ parent, data = galton)
sqrt((sum(fit$residuals)^2)/(n - 2))
sqrt(sum(fit$residuals^2)/(n - 2))
summary(fit)$sigma
deviance(fit)/(n - 2)
deviance(fit)/(n-2)
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit)
1 - (sRes/sTot)
1-(sRes/sTot)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$child, galton$parent)^2
swirl()
q('no')
library(shiny)
shiny()
library(swirl)
swirl()
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ Constant + Girth + Height -1, galton)
fit <- lm(Volume ~ Constant + Girth + Height -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
q('no')
rm(df_tasting)
library(swirl)
swirl()
all <- lm(Fertility ~ ., data = swiss)
summary(all)
summary(lm(Fertility ~ agriculture, data = swiss))
summary(lm(Fertility ~ Agriculture, data = swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ . + ec, data = swiss)
coef(efit) - coef(all)
coef(all) - coef(efit)
all$coefficients - efit$coefficients
q('yes')
rm(list = ls())
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
summary(lm(y ~ x))
lm1 <- summary(lm(y ~ x))
deviance(lm1)
deviance(lm1$residuals)
lm1$residuals
(lm1$residuals^2)/(length(x)-2)
sum((lm1$residuals^2))/(length(x)-2)
sd(lm1$residuals)
sqrt(sum((lm1$residuals^2))/(length(x)-2))
data("mtcars")
lmCars <- lm(mpg ~ weight, mtcars)
lmCars <- lm(mpg ~ wt, mtcars)
confint(predict(lmCars, newdata = data.frame(wt = mean(mtcars$wt))))
predict(lmCars, newdata = data.frame(wt = mean(mtcars$wt)), interval = "confidence")
?mtcars
summary(mtcars$wt)
predict(lmCars, newdata = data.frame(wt = 3), interval = "confidence")
predict(lmCars, newdata = data.frame(wt = 3), interval = "prediction")
predict(lmCars, newdata = data.frame(wt = 3), interval = "confidence")
confint(lmCars)
summary(lmCars)
sum(lmCars$residuals)
lmCars2 <- lm(mpg - mean(mpg) ~ wt - mean(wt), mtcars)
lmCars2 <- lm((mpg - mean(mpg)) ~ (wt - mean(wt)), mtcars)
lmCars2 <- lm((mtcars$mpg - mean(mtcars$mpg)) ~ (mtcars$wt - mean(mtcars$wt)))
mtcars$wt - mean(mtcars$wt)
mtcars$mpg - mean(mtcars$mpg)
rm(list = ls())
library(swirl)
swirl()
play()
View(InsectSprays)
count(unique(InsectSprays$spray))
length(unique(InsectSprays$spray))
nxt()
6
swirl()
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays, 15)
sA
summary(InsectSprays$spray)
summary(InsectSprays$[,2])
summary(InsectSprays[,2])
sapply(InsectSprays, class)
fit <- lm(count ~ spray, data = InsectSprays)
summary(fit)
summary(fit)$coef
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray - 1, data = InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(InsectSprays ~ spray2)
fit2 <- lm(InsectSprays$count ~ spray2)
summary(fit2)$coef
mean(sC)
(fit$coefficients[2] - fit$coefficients[3])1.6011
(fit$coefficients[2] - fit$coefficients[3])/1.6011
(fit$coefficients[2] - fit$coefficients[3])/1.601110
(fit$coef[2] - fit$coef[3])/1.601110
(fit$coef[2] - fit$coef[3])/1.6011
swirl()
swirl()
swirl()
dim(hunger)
948
names(hunger)
fit <- lm(Numeric ~ Year, data = hunger)
summary(fit)$coef
lmF <- lm(Numeric ~ Year, data = hunger[hunger$Sex=="Female",])
lmF <- lm(Numeric[hunger$Sex=="Female"] ~ Year[hunger$Sex=="Female"])
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"] ~ hunger$Year[hunger$Sex=="Female"])
play()
names(hunger)
table(hunger$Sex)
lmM <- lm(hunger$Numeric[hunger$Sex=="Male"] ~ hunger$Year[hunger$Sex=="Male"])
nxt()
lmM <- lm(hunger$Numeric[hunger$Sex=="Male"] ~ hunger$Year[hunger$Sex=="Male"])
lmBoth <- lm(Numeric ~ Year + Sex, data = hunger)
summary(lmBoth)
lmInter <- lm(Numeric ~ Year + Sex + Sex*Year, data = hunger)
summary(lmInter)
swirl()
swirl()
swirl()
swirl()
fit <- lm(y ~ x, out2)
plot(fit, which = 1)
fitno <- lm(y ~ x, out[-1,])
fitno <- lm(y ~ x, out2[-1,])
plot(fitno, which = 1)
coef(fit) - coef(fitno)
View(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1 - resid(fit)[1]/resno
View(hatvalues(fit))
sigma <- sqrt(deviance(fit)/fit$df.residual)
rstd <- resid(fit)/(sigma*sqrt(1-fit$hatvalues(fit)))
rstd <- resid(fit)/(sigma*sqrt(1-hatvalues(fit)))
View(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(deviance(fitno)/fitno$df.residual)
resid(fit)[1]/(sigma1 * sqrt(1-hatvalues(fit)[1]))
rstudent(fit)[1]
View(rstudent(fit))
dy <- predict(fitno, out2) - predict(fit, out2)
sum(dy^2)/(2*sigma^2)
plot(fit, which = 5)
q('no')
rm(list = ls())
setwd("Desktop/PracticalML")
df_trainData <- read.csv("pml-training.csv")
df_testData <- read.csv("pml-testing.csv")
colMeans(is.na(df_trainData))
barplot(colMeans(is.na(df_trainData)))
names(colMeans(is.na(df_trainData)))
names(colMeans(is.na(df_trainData)))[colMeans(is.na(df_trainData)) > 0.9]
varsToDrop <- names(colMeans(is.na(df_trainData)))[colMeans(is.na(df_trainData)) > 0.9]
dim(df_trainData[,-varsToDrop])
dim(df_trainData[,-c(varsToDrop)])
df_trainData %>%
select(-varsToDrop) -> df_trainData
library(dplyr)
df_trainData %>%
select(-varsToDrop) -> df_trainData
df_testData %>%
select(-varsToDrop) -> df_testData
barplot(colMeans(is.na(df_trainData)))
colMeans(is.na(df_trainData))
library(caret)
nearZeroVar(df_trainData, saveMetrics = TRUE)
nearZeroVar(df_trainData, saveMetrics = TRUE)$nzv
dim(df_trainData[, -nearZeroVar(df_trainData, saveMetrics = TRUE)$nzv])
dim(df_trainData[, nearZeroVar(df_trainData, saveMetrics = TRUE)$nzv==FALSE])
vars_nzv <- nearZeroVar(df_trainData, saveMetrics = TRUE)$nzv
df_trainData <- df_trainData[, vars_nzv==FALSE]
df_testData <- df_testData[, vars_nzv==FALSE]
View(df_trainData)
View(df_testData)
df_trainData <- df_trainData[,-1]
df_testData <- df_testData[,-1]
View(head(df_trainData))
inTrain <- createDataPartition(df_trainData$classe, p = 0.7, list = FALSe)
inTrain <- createDataPartition(df_trainData$classe, p = 0.7, list = FALSE)
train <- df_trainData[inTrain, ]
test <- df_trainData[-inTrain, ]
mdl_rf <- train(classe ~ ., train)
?train
mdl_rf <- train(classe ~ ., method = "rf", data = train)
mdl_rf
confusionMatrix(test$classe, predict(mdl_rf, test))
save(mdl_rf, file = "mdl_rf.RData")
mdl_xgb <- train(classe ~ ., method = "xgboost", data = train)
mdl_xgb
confusionMatrix(test$classe, predict(mdl_xgb, test))
save(mdl_xgb, file = "mdl_xgb.RData")
mdl_xgb <- train(classe ~ ., method = "xgbDART", data = train)
getwd()
q('yes')
install.packages("doParallel")
library(doParallel)
cl <- makePSOCKcluster(4)
registerDoParallel(cl)
mdl_rf <- train(classe ~ ., method = "rf", data = train)
library(caret)
mdl_rf <- train(classe ~ ., method = "rf", data = train)
rm(list = ls())
q('no')
